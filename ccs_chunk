#!/bin/bash
#
# Chunk uses slurm's job array feature to easily generate chunked ccs jobs.
# Argument 1 is PATH/TO/INPUT.BAM/. Argument 2 specifies ccs <options> and is optional.
# By default, ccs_chunk runs ccs with all flags. Pass ccs chunk "--basic" as arg 2 to run ccs with no flags.
# Running ccs with all flags incorporates the most possible run data in output BAM.
# Visit ccs.how for info about pacbio's ccs program.

# ALLOCATE COMPUTE RESOURCES
CCS_MEM_PER_CPU=2
CCS_NUM_TASKS=8
MERGE_MEM_PER_CPU=4
MERGE_NUM_TASKS=8

# INITIALIZE IMPORTANT VARIABLES
CCS_BIN="/fslhome/aknaupp/miniconda3/bin/ccs"
BASE_DIR="/lustre/scratch/grp/fslg_dnasc"
FILEPATH="$( cd "$(dirname $1)" && pwd)"/"$(basename $1)" # absolute path to file
FILENAME=$(basename ${FILEPATH%.bam}) # extract the filename from the path, without .bam extension.
FILESIZE=$(stat -c%s "$FILEPATH") # NUM_CHUNKS is optimized depending on the size of the input file.
CHUNK_SIZE=8000000000 # an allocation of 8 cores with 2GB mem per core can process a 8GB chunk in ~1hr.
NUM_CHUNKS=$((($FILESIZE + $CHUNK_SIZE) / $CHUNK_SIZE)) # Bash truncates by default. add (denom - 1) to the numerator to round up.
JOB_DIR="$BASE_DIR/${FILENAME}.ccs"

# CREATE UNIQUE JOB DIRECTORY
TEMP_DIR=$JOB_DIR
for i in {1..100}
do
  if [[ -d "$TEMP_DIR" ]] # if job directory exists
  then
    TEMP_DIR="${JOB_DIR}_${i}" # append value of i and check again
  else
    break # job directory is unique, exit loop
  fi
done
JOB_DIR=$TEMP_DIR
mkdir $JOB_DIR > /dev/null 2>&1 # squelch mkdir's output

# GRAB ANY OTHER RUN DATA IN SAME DIR AS SUBREADS FILE
SOURCE_DIR=$( cd "$(dirname $1)" && pwd) # directory containing subreads file and other related files
MOVIE_ID=${FILENAME%.subreads} # pacbio subreads files are formatted as follows: <movieID>.subreads.bam
cp $SOURCE_DIR/${MOVIE_ID}.subreadset.xml $JOB_DIR/.
cp $SOURCE_DIR/.${MOVIE_ID}.run.metadata.xml $JOB_DIR/.
cp $SOURCE_DIR/.${MOVIE_ID}.metadata.xml $JOB_DIR/.
# FIXME: CHECK that files exist before attempting to copy over. Report results.

# GENERATE SLURM SUBMISSION FILE
MODE="ALL"
ARGS=" --chunk \$SLURM_ARRAY_TASK_ID/${NUM_CHUNKS} $FILEPATH ${FILENAME}_chunk_\${SLURM_ARRAY_TASK_ID}.ccs.bam"
if [[ $2 != "--basic" ]]
then
  ARGS=" --all --all-kinetics --subread-fallback$ARGS"
else
  MODE="BASIC"
fi
cat > $JOB_DIR/ccs_array_job.sh <<- EOF
#!/bin/bash
#SBATCH --job-name=${FILENAME}.ccs_MODE=${MODE}
#SBATCH --time=2:00:00 --mem-per-cpu=${CCS_MEM_PER_CPU}GB --ntasks=$CCS_NUM_TASKS --nodes=1
#SBATCH --mail-user=adknaupp@gmail.com --mail-type=FAIL

mkdir $JOB_DIR/chunk_\$SLURM_ARRAY_TASK_ID
cd $JOB_DIR/chunk_\$SLURM_ARRAY_TASK_ID

${CCS_BIN}${ARGS}
EOF

# REPORT TO USER
if [[ $MODE == "ALL" ]]
then
  echo "Running CCS with all flags"
else
  echo "Running CCS at basic level (only reads >Q20, no kinetics)"
fi
echo "CHUNKS: $NUM_CHUNKS"

# SUBMIT SBATCH JOB AND COLLECT JOB NUMBER
mkdir $JOB_DIR/slurm.out
cd $JOB_DIR/slurm.out
SBATCH_OUTPUT=$( sbatch -a 1-$NUM_CHUNKS $JOB_DIR/ccs_array_job.sh ) # <-a> flag requests an array job with NUM_CHUNKS array tasks.
echo $SBATCH_OUTPUT

REGEX="Submitted batch job ([0-9]+)"
SLURM_JOB_ID=""

if [[ $SBATCH_OUTPUT =~ $REGEX ]] # if submission fails, ccs_chunk exits
then
  SLURM_JOB_ID=${BASH_REMATCH[1]}
else
  echo 'ccs_chunk has exited, any further processing will have to be completed manually.'
  exit 1
fi

# SCONTROL LISTENER CHECKS FOR COMPLETION
touch $JOB_DIR/scontrol.out
touch $JOB_DIR/listener.out
INFILE="$JOB_DIR/scontrol.out"
echo 'ccs_chunk is monitoring the ccs job status via scontrol and will proceed to merge all chunks once all complete.'
while [ 1 ]
do
  scontrol show job $SLURM_JOB_ID > $INFILE

  if [[ $( egrep 'JobState=' $INFILE ) == "" ]] # verify that valid output is being obtained from scontrol
  then
    echo 'ccs_chunk has exited due to a failure to obtain valid scontrol output.' >> $JOB_DIR/listener.out
    echo 'any further processing will have to be completed manually.' >> $JOB_DIR/listener.out
    exit 1
  fi

  if [[ $( egrep 'JobState=(P|R|CA|CON)' $INFILE ) == "" ]] # check if chunking jobs are done
  then
    echo 'all jobs successfully completed' >> $JOB_DIR/listener.out
    break # BREAK
  else
    if [[ $( egrep 'JobState=CANCEL' $INFILE ) ]] # if any chunk tasks are cancelled, ccs_chunk must exit
    then
      echo 'ccs_chunk has exited since one or more chunk tasks were cancelled by scontrol.' >> $JOB_DIR/listener.out
      echo 'any further processing will have to be completed manually.' >> $JOB_DIR/listener.out
      exit 1
    fi
  fi

  sleep 60
done

# SET UP MERGE JOB
INPUT_DIRS="chunk_1/${FILENAME}_chunk_1.ccs.bam"

for i in {2..1000}
do
  CHUNK_DIR="chunk_${i}"
  if [[ -d $CHUNK_DIR ]] # if job directory exists
  then
    INPUT_DIRS="$INPUT_DIRS ${CHUNK_DIR}/${FILENAME}_chunk_${i}.ccs.bam"
  else
    break # all chunk dirs have been added to input dirs
  fi
done

cat > $JOB_DIR/merge_job.sh <<- EOF
#!/bin/bash
#SBATCH --job-name=merge_${FILENAME}.ccs
#SBATCH --time=00:30:00 --mem-per-cpu=${MERGE_MEM_PER_CPU}GB --ntasks=$MERGE_NUM_TASKS --nodes=1
#SBATCH --mail-user=adknaupp@gmail.com --mail-type=END --mail-type=FAIL

/fslgroup/fslg_dnasc/smrtlink/8.0.0/current/bundles/smrttools/current/private/otherbins/runtime/bin/pbmerge -o $JOB_DIR/${FILENAME}.ccs.bam $JOB_DIR/$INPUT_DIRS
EOF

sbatch $JOB_DIR/merge_job.sh
